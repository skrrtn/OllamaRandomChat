Will add a correct readme when things get going. Until then, this is all you get.

Run the compose file, it should give you the NGINX, PHP and Ollama servers.
In the Ollama container, pull the model file used with the command "ollama pull dolphin-llama3:8b"

Uses all default ports, edit to your liking. Make sure nothing conflicts.

Happy Chatting! More to come!
